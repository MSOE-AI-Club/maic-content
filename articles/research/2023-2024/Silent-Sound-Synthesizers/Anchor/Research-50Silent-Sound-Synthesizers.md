This group is working on a project to generate realistic audio from silent videos using a novel deep learning approach. They use a Seq2Seq model with a VQ-VAE encoder and a SoundStream decoder to capture the videoâ€™s visual context and produce corresponding sound waves. They test their model on a subset of Youtube8M videos and show its potential for various applications.
